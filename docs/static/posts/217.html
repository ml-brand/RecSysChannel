<!doctype html>
<html lang="ru">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Рекомендательная [RecSys Channel] — пост #217</title>
  <meta name="description" content=" KVzap: Fast, Adaptive, and Faithful KV Cache Pruning   Сегодня посмотрим на совсем свежую  статью  от NVIDIA о сжатии KV-кэша. KV-кэш — это сохраненные K- и V-стейты трансформера для последующей авто" />
  <link rel="icon" href="../../favicon.ico" sizes="any" />
  <link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32.png" />
  <link rel="apple-touch-icon" href="../../apple-touch-icon.png" />

  <link rel="canonical" href="https://ml-brand.github.io/RecSysChannel/static/posts/217.html" />
  <meta property="og:type" content="article" />
  <meta property="og:title" content="Рекомендательная [RecSys Channel] — пост #217" />
  <meta property="og:description" content=" KVzap: Fast, Adaptive, and Faithful KV Cache Pruning   Сегодня посмотрим на совсем свежую  статью  от NVIDIA о сжатии KV-кэша. KV-кэш — это сохраненные K- и V-стейты трансформера для последующей авто" />
  <meta property="og:image" content="https://ml-brand.github.io/RecSysChannel/assets/media/thumbs/217_480.webp" />
  <meta property="og:image:alt" content="Рекомендательная [RecSys Channel]" />
  <meta property="article:published_time" content="2026-01-29T09:14:01+00:00" />
  <meta property="article:author" content="Рекомендательная [RecSys Channel]" />
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:image" content="https://ml-brand.github.io/RecSysChannel/assets/media/thumbs/217_480.webp" />
  <link rel="stylesheet" href="../../style.css" />
  <script src="../../metrika.js"></script>
</head>
<body data-index-href="../index.html">
  <header class="header">
    <div class="container">
      <div class="title-grid single-title">
        <a class="grid-avatar" href="#" target="_blank" rel="noopener">
          <img id="channelAvatar" class="channel-avatar" src="../../assets/channel_avatar.jpg" alt="Аватар канала"  />
        </a>
        <div class="grid-main">
          <div class="title-head">
            <a class="back-link" href="../index.html">← Ко всем постам</a>
            <a class="badge-chip" id="siteTitleWrap" href="#" target="_blank" rel="noopener"><h1 id="siteTitle">Рекомендательная [RecSys Channel]</h1></a>
            <div class="hero-actions">
              <a id="subscribeBtn" class="subscribe-btn" href="https://t.me/+3NrSk0BmQ-QzZTMy" target="_blank" rel="noopener" >Подписаться</a>
              <a class="icon-btn" href="../../post.html?id=217" aria-label="Открыть динамическую страницу поста">↺</a>
              <button id="themeToggle" class="icon-btn" type="button" aria-label="Переключить тему"></button>
            </div>
          </div>
        </div>
      </div>
    </div>
  </header>

  
  <div id="promoBanner" class="promo-banner" hidden>
    <div class="container promo-inner">
      <span class="promo-text"><a href="https://t.me/addlist/5NH3RoVejEI1MGEy">Подпишись на все наши ML каналы. Они классные, отвечаем!</a></span>
      <button id="promoClose" class="promo-close" type="button" aria-label="Скрыть плашку">×</button>
    </div>
  </div>
  

  <main class="container single-page">
    <article id="postContainer" class="post post-page" data-post-id="217">
      <div class="post-header">
        <div class="right"><span class="post-date" data-iso-date="2026-01-29T09:14:01+00:00">2026-01-29 09:14 UTC</span></div>
      </div>
      <div class="post-body"><strong>KVzap: Fast, Adaptive, and Faithful KV Cache Pruning<br></strong><br>Сегодня посмотрим на совсем свежую <a href="https://arxiv.org/abs/2601.07891v1" rel="nofollow noopener noreferrer">статью</a> от NVIDIA о сжатии KV-кэша. KV-кэш — это сохраненные K- и V-стейты трансформера для последующей авторегрессивной генерации токенов в декодере. В первую очередь проблема сжатия возникает на стадии генерации в LLM, однако она актуальна и для ускорения инференса рекомендательных моделей, например, имеющих encoder-decoder-архитектуру. <br><br>Размер KV-кэша линейно зависит от числа слоёв трансформера L, от числа аттеншн-голов H, от длины входной последовательности T и от размерности векторов D. Таким образом, он имеет размерность (2, L, H, T, D), где 2 соответствует хранению K- и V-кэшей в одном тензоре. Сжатие по L-размерности достигается чередованием обычных MHA-слоёв и слоёв со Sliding Window Attention (SWA): <a href="https://openai.com/index/introducing-gpt-oss/" rel="nofollow noopener noreferrer">GPT-OSS-120B</a>, <a href="https://arxiv.org/abs/2503.19786" rel="nofollow noopener noreferrer">Gemma3</a>, <a href="https://arxiv.org/abs/2510.26692" rel="nofollow noopener noreferrer">Kimi-Linear</a>, и др. Для сжатия по размерности H применяют Grouped Query Attention (GQA), в котором одни и те же KV-головы используются в нескольких Q-головах: <a href="https://arxiv.org/abs/2407.21783" rel="nofollow noopener noreferrer">Llama3</a>, <a href="https://arxiv.org/abs/2508.06471" rel="nofollow noopener noreferrer">GLM 4.5</a>, <a href="https://arxiv.org/abs/2505.09388" rel="nofollow noopener noreferrer">Qwen3-235B-A22B</a>. Вдоль размерности D сжатия добиваются с использованием хранения латентных представлений KV-векторов значительно меньшей размерности — Multi-head Latent Attention (MLA): <a href="https://arxiv.org/abs/2405.04434" rel="nofollow noopener noreferrer">DeepSeek V2</a>. <br><br>Текущая SOTA для сжатия вдоль размерности T — <a href="https://arxiv.org/abs/2505.23416" rel="nofollow noopener noreferrer">KVzip</a>, который: <br><br>1. получает входной промпт пользователя; <br>2. просит модель его повторить, аугментируя промпт следующим образом: <em>«user:</em> &lt;input prompt&gt;<em>. Repeat the previous context exactly. assistant: »</em>;<br>3. для каждой KV-головы для каждого вектора k_i из input prompt запоминают наибольший по длине повторённого промпта вес аттеншна (а в случае GQA максимум берётся и по группе Q-голов);<br>4. фиксированный процент K_i и v_i, соответствующих наименьшим запомненным весам, удаляются;<br>5. сжатый промпт подаётся модели.<br> <br>Во-первых, такая схема скоринга очень дорога. Во-вторых, она применима только к стадии cache prefilling — стадия cache decoding сохраняется целиком. Последняя проблема особенно актуальна в контексте рассуждающих моделей, которые на стадии декодинга генерируют тысячи токенов. <br><br>В работе предлагают дистиллировать слегка модифицированные скоры KVzip в легковесный MLP. Для каждого слоя трансформера и каждого входного скрытого состояния MLP предсказывает вектор скоров из H (число KV-голов) компонент, после чего откидываются KV-пары, скоры которых не превосходят некоторый порог. Таким образом, степень сжатия зависит от информативности промпта. Локальный контекст из ближайших 128 токенов, однако, сохраняется полностью. MLP обучается поверх обученной модели на специальном датасете, содержащем целевые скоры KV-пар. <br><br>Поскольку MLP не добавляет значительной вычислительной сложности и применяется к входным токенам поточечно, KVzap можно использовать как во время prefilling’a, так и во время декодинга. Сжатие prefilling-стадии также становится дешевле. <br><br>Эвалятся авторы на Qwen3-8B, Llama-3.1-8B-Instruct, и Qwen3-32B, KV-кэш удаётся сжать в 2–4 раза при незначительных потерях качества. <br><br>@RecSysChannel<br>Разбор подготовил <em><tg-emoji emoji-id="5224192932302565805">❣</tg-emoji></em> Сергей Макеев<div class="media"><img class="media-img" loading="lazy" src="../../assets/media/thumbs/217_480.webp" srcset="../../assets/media/thumbs/217_480.webp 480w, ../../assets/media/217.jpg 1200w" sizes="(max-width: 768px) 100vw, 800px" alt="" data-post-id="217" data-image-index="0" /></div></div>
      <div class="actions">
        <span>1 054 просмотров · 19 реакций</span>
        <span class="action-links"><a href="https://t.me/RecSysChannel/217" target="_blank" rel="noopener">Открыть в Telegram</a> · <a href="../index.html">К списку постов</a> · <a href="./217.html">Ссылка на этот пост</a></span>
      </div>
    </article>

    <div class="pager single-nav">
      <a id="prevPost" class="nav-link" href="./218.html" style="visibility:visible">← Более новый</a>
      <a id="nextPost" class="nav-link" href="./210.html" style="visibility:visible">Более старый →</a>
    </div>
  </main>

  <footer class="footer">
    <div class="container">
      <div class="footer-inner">
        <span>based on <a href="https://github.com/ml-brand/tg-to-gh-pages" target="_blank" rel="noopener">tg-to-gh-pages</a> (created by <a href="https://github.com/ml-brand" target="_blank" rel="noopener">ML Brand</a>)</span>
        <a id="repoLink" href="https://github.com/ml-brand/tg-to-gh-pages" target="_blank" rel="noopener">Do the same with your channel.</a>
        <span class="footer-links">
          static copy ·
          <a href="../../feed.xml" target="_blank" rel="noopener">RSS</a> ·
          <a href="../../atom.xml" target="_blank" rel="noopener">Atom</a>
        </span>
      </div>
    </div>
  </footer>

  <script>
    window.__STATIC_POSTS = [{"id": 217, "media": [{"kind": "photo", "path": "../../assets/media/217.jpg", "thumb": "../../assets/media/thumbs/217_480.webp", "size": 71435, "mime": "image/jpeg", "name": null}]}];
    window.__STATIC_META = {"title": "Рекомендательная [RecSys Channel]", "username": "RecSysChannel", "channel": "RecSysChannel", "last_sync_utc": "2026-02-05T15:26:33Z", "posts_count": 105, "last_seen_message_id": 218, "stats": {"new": 104, "updated": 27, "media_downloaded": 104}, "avatar": "assets/channel_avatar.jpg", "meta_schema_version": "1.0.0", "posts_schema_version": "1.0.0"};
  </script>
  <script src="../../common.js"></script>
  <script src="../../static.js"></script>
</body>
</html>
